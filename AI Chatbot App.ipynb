{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1066f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676f906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec100e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78154f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.5.1-py3-none-any.whl (142 kB)\n",
      "     -------------------------------------- 142.2/142.2 kB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.2)\n",
      "Collecting google-ai-generativelanguage==0.6.2\n",
      "  Downloading google_ai_generativelanguage-0.6.2-py3-none-any.whl (664 kB)\n",
      "     ------------------------------------- 664.5/664.5 kB 21.1 MB/s eta 0:00:00\n",
      "Collecting google-api-core\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "     ---------------------------------------- 138.3/138.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pydantic in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-generativeai) (2.6.4)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-generativeai) (2.29.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.126.0-py2.py3-none-any.whl (12.6 MB)\n",
      "     --------------------------------------- 12.6/12.6 MB 21.8 MB/s eta 0:00:00\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.8/48.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.63.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.9/96.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.62.1)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Downloading grpcio_status-1.62.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rjsek\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Installing collected packages: uritemplate, proto-plus, httplib2, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.2 google-api-core-2.18.0 google-api-python-client-2.126.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.1 grpcio-status-1.62.1 httplib2-0.22.0 proto-plus-1.23.0 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "! pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c8c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e14618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb5b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keys/.gemini.txt\")\n",
    "key = f.read()\n",
    "\n",
    "genai.configure(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a646d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9620dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa64079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb610e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompting the Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-pro\")\n",
    "\n",
    "user_prompt = \"\"\"Complete the following:\n",
    "                In our solar system, Earth is a \"\"\"\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-pro\")\n",
    "\n",
    "user_prompt = \"\"\"Generate some factual information to complete the following in 2-3 lines:\n",
    "                In our solar system, Earth is a \"\"\"\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a795c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1efe4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce3fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\", \n",
    "                              system_instruction=\"\"\"Generate some factual information to complete the user input. \n",
    "                              Completion must have maximum 2-3 lines.\"\"\")\n",
    "\n",
    "user_prompt = \"\"\"In our solar system, Earth is a \"\"\"\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09b62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation AI using Gemini AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cabe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c018f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d64f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef7a2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Explain the concept of Logistic Regression.\"\n",
    "\n",
    "response = chat.send_message(user_input)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1497c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5437e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in chat.history:\n",
    "    print(f\">> {message.role}: {message.parts[0].text}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f8280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade934ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# App Code - Basic visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21aee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "\n",
    "st.title(\"AI Chatbot\")\n",
    "\n",
    "# Read the api key\n",
    "f = open(\"API Key.txt\")\n",
    "key = f.read()\n",
    "\n",
    "# Configure the API Key\n",
    "genai.configure(api_key=key)\n",
    "\n",
    "# Initiate a Gen AI Model\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
    "                              system_instruction=\"\"\"You are a helpful AI Assistant.\"\"\")\n",
    "\n",
    "# Chat History\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state[\"chat_history\"] = []\n",
    "\n",
    "# Chat Object\n",
    "chat = model.start_chat(history=st.session_state[\"chat_history\"])\n",
    "\n",
    "for msg in chat.history:\n",
    "    st.chat_message(msg.role).write(msg.parts[0].text)\n",
    "\n",
    "user_prompt = st.chat_input()\n",
    "\n",
    "if user_prompt:\n",
    "    st.chat_message(\"user\").write(user_prompt)\n",
    "    response = chat.send_message(user_prompt,stream=True)\n",
    "    st.chat_message(\"bot\").write(response.text)\n",
    "    st.session_state[\"chat_history\"] = chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559fe27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5334e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Visual [UI/UX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c2897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set page title and favicon\n",
    "st.set_page_config(page_title=\"Data Science Tutor\", page_icon=\"ðŸ“Š\")\n",
    "\n",
    "# Title and description\n",
    "st.title(\"ðŸ¤– Data Science Tutor\")\n",
    "st.markdown(\"*Powered by Gemini 1.5 Pro*\")\n",
    "st.markdown(\"Hello!, I'm the Data Science Tutor! I'm here to help with your data science questions.\")\n",
    "\n",
    "# Read the API key from a file\n",
    "with open(\"API Key.txt\", \"r\") as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Configure the API Key\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize Gen AI model\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
    "                              system_instruction=\"You are a helpful AI Assistant.\")\n",
    "\n",
    "# Chat history\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state[\"chat_history\"] = []\n",
    "\n",
    "# Chat object\n",
    "chat = model.start_chat(history=st.session_state[\"chat_history\"])\n",
    "\n",
    "# Function to display chat messages\n",
    "def display_messages():\n",
    "    for msg in chat.history:\n",
    "        if msg.role == \"system\":\n",
    "            st.info(msg.parts[0].text)\n",
    "        elif msg.role == \"user\":\n",
    "            st.markdown(f\"**You:** {msg.parts[0].text}\")\n",
    "        else:\n",
    "            st.markdown(f\"**Bot:** {msg.parts[0].text}\")\n",
    "\n",
    "# Display chat history\n",
    "display_messages()\n",
    "\n",
    "# User input\n",
    "user_prompt = st.text_input(\"Ask here:\", key=\"user_input\")\n",
    "\n",
    "# Handle user input\n",
    "if st.button(\"Ask\"):\n",
    "    if user_prompt:\n",
    "        # Display user message\n",
    "        st.markdown(f\"**You:** {user_prompt}\")\n",
    "        # Get response from AI model\n",
    "        response = chat.send_message(user_prompt)\n",
    "        # Display bot response\n",
    "        st.markdown(f\"**Bot:** {response.text}\")\n",
    "        # Update chat history\n",
    "        st.session_state[\"chat_history\"] = chat.history\n",
    "    else:\n",
    "        st.warning(\"Please enter a question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a71a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbde25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "\n",
    "# Set page title and favicon\n",
    "st.set_page_config(page_title=\"Data Science Tutor\", page_icon=\"ðŸ“Š\")\n",
    "\n",
    "# Title and description\n",
    "st.title(\"ðŸ¤– Data Science Tutor\")\n",
    "st.markdown(\"*Powered by Gemini 1.5 ProðŸš€*\")\n",
    "st.markdown(\"Hello!, I'm Gemini the Data Science Tutor! I'm here to help with your data science questions.\")\n",
    "\n",
    "# Read the api key\n",
    "with open(\"API Key.txt\", \"r\") as f:\n",
    "    key = f.read().strip()\n",
    "\n",
    "# Configure the API Key\n",
    "genai.configure(api_key=key)\n",
    "\n",
    "# Initiate a Gen AI Model with system instruction\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro-latest\",\n",
    "    system_instruction=\"You are a helpful AI Assistant,Provide accurate and relevant information.\"\n",
    ")\n",
    "\n",
    "# Chat History\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state[\"chat_history\"] = []\n",
    "\n",
    "# Chat Object\n",
    "chat = model.start_chat(history=st.session_state[\"chat_history\"])\n",
    "\n",
    "for msg in chat.history:\n",
    "    st.chat_message(msg.role).write(msg.parts[0].text)\n",
    "\n",
    "# Function to stream response data\n",
    "def stream_data(response):\n",
    "    for word in response.split(\" \"):\n",
    "        yield word + \" \"\n",
    "        time.sleep(0.06)\n",
    "\n",
    "user_prompt = st.chat_input()\n",
    "\n",
    "if user_prompt:\n",
    "    st.chat_message(\"user\").write(user_prompt)\n",
    "    try:\n",
    "        response = chat.send_message(user_prompt).parts[0].text\n",
    "        st.chat_message(\"AI\").write(stream_data(response))\n",
    "    except genai.generation_types.StopCandidateException as e:\n",
    "        st.warning(f\"StopCandidateException: {e}\")\n",
    "    st.session_state[\"chat_history\"] = chat.history\n",
    "\n",
    "# Run the App\n",
    "# streamlit run app.py    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce36b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
